#!/usr/bin/env python3

import sys
import os
import math
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont
from Bio.Blast import NCBIXML
from taxfinder import TaxFinder
from collections import defaultdict

from phylogenetics import phylogenetics as phylo


class ConfigReader():
	'''
	The ConfigReader reads the `limits.txt` and `proteinlist.txt` and return the contents in different formats upon request.
	'''

	def __init__(self):
		'''
		Initiates the class.
		'''

		self.limits_dict = {'default': (1e-30, 50)}
		self.proteins = []
		self.protein_files = []
		self.taxa_to_show = []
		self.hm_colors = {}
		self.clustering_method = ''

		self._read_proteinlist()
		self._read_limits()
		self._read_heatmap_values()


	def _read_limits(self):
		'''
		Reads `limits.txt` and saves the content as dictionary to be used by the `get_limits()` method.
		'''

		with open('limits.txt') as f:
			self.limits_dict = {'default': (1e-30, 50)}
			for line in f:
				line = line.split('#')[0].rstrip()
				if not line:
					continue
				lline = line.split()
				try:
					evalue = float(lline[1])
				except ValueError:
					evalue = self.limits_dict['default'][0]
				try:
					length = int(lline[2])
				except ValueError:
					length = self.limits_dict['default'][1]
				self.limits_dict[lline[0]] = (evalue, length)


	def get_limits(self):
		'''
		Reads `limits.txt` and returns a dict in the format: {'protein': (evalue, length), ...} where evalue is the negative exponent of the evalue (int) and length is the length limit for the protein (int).

		:uses: `limits.txt`
		:returns: A dictionary with limits as described above
		'''

		return self.limits_dict


	def _read_proteinlist(self):
		'''
		Reads `proteinlist.txt` and saves the content as lists to be used by the get* methods.
		'''

		with open('proteinlist.txt') as f:
			self.proteins = []
			self.protein_files = []
			for line in f:
				line = line.split('#')[0].strip()
				if not line:
					continue
				elems = line.split()
				if elems[0] not in self.proteins:
					self.proteins.append(elems[0])
					self.protein_files.append([])
				pidx = self.proteins.index(elems[0])
				self.protein_files[pidx].append(os.path.splitext(elems[1])[0])


	def get_protein_names(self, prefix = '', suffix = ''):
		'''
		Returns a set of proteins in the format: {'protein1', 'protein2', ...}. A prefix (a path) can be added as well as a suffix. get_protein_names('abc/', '.txt') will turn 'protein1' into 'abc/protein1.txt'.

		:param prefix: A string to be prepended before the name
		:param suffix: A string to be appended after the name
		:returns: A set with proteins
		'''

		return set((prefix + protein + suffix for protein in self.proteins))


	def get_protein_files(self, prefix = '', suffix = ''):
		'''
		Returns a set of filenames in the format: {'proteinfile1', 'proteinfile2', ...}. The files are just the basenames without suffix. A prefix (a path) can be added as well as a suffix. get_protein_files('abc/', '.txt') will turn 'file1' into 'abc/file1.txt'.

		:param prefix: A string to be prepended before the filename
		:param suffix: A string to be appended after the filename
		:returns: A set of filenames
		'''

		return set((prefix + fn + suffix for proteinlist in self.protein_files for fn in proteinlist))


	def get_protein_dict(self, prefix = '', suffix = ''):
		'''
		Returns a dict with proteins and their respective file names in the format: {'protein': set('file1', 'file2', ...), ...}. The files are just the basenames without suffix. A prefix (a path) can be added as well as a suffix. get_protein_dict('abc/', '.txt') will turn 'file1' into 'abc/file1.txt'.

		:param prefix: A string to be prepended before the filename
		:param suffix: A string to be appended after the filename
		:returns: A dictionary as described above
		'''

		ret = {}
		for i in range(len(self.proteins)):
			ret[self.proteins[i]] = set((prefix + fn + suffix for fn in self.protein_files[i]))

		return ret


	def _read_heatmap_values(self):
		'''
		Reads `heatmap_config.txt` and saves the content as lists and dicts to be used by the get* methods.
		'''

		with open('heatmap_config.txt') as f:
			self.taxa_to_show = []
			self.hm_colors = {}
			self.clustering_method = ''

			mode = ''
			modes = {'TAXA_TO_SHOW': 'taxa_to_show', 'COLORS': 'colors', 'ALGO': 'clustering'}

			clustering_methods = {'single', 'complete', 'average', 'weighted', 'centroid', 'median', 'ward'}

			for line in f:
				line = line.rstrip()
				if not line or line.startswith('#'):
					continue

				if line in modes:
					mode = modes[line]

				elif mode == 'taxa_to_show':
					self.taxa_to_show.append(line)

				elif mode == 'colors':
					lline = line.split()
					self.hm_colors[lline[0]] = lline[1]

				elif mode == 'clustering':
					if line in clustering_methods:
						self.clustering_method = line
					else:
						raise ValueError('Error in heatmap_config.txt. Unknown clustering method: {}!'.format(line))

				else:
					raise ValueError('Error in heatmap_config.txt. No mode selected and {} found!'.format(line))


	def get_heatmap_taxa(self):
		'''
		Returns a list with the taxa to show.

		:returns: A list of taxa
		'''

		return self.taxa_to_show


	def get_heatmap_colors(self):
		'''
		Returns a dict with the colors in the form {'letter': 'color_code', ...}

		:returns: A dict with colors
		'''

		return self.hm_colors


	def get_heatmap_clustering(self):
		'''
		Returns the clustering method of choice

		:returns: A string with the clustering method
		'''

		return self.clustering_method

	# end ConfigReader


def _my_get_basename(name):
	'''
	Strips the path and the extension from a filename. E.g. /a/path/to/file.png -> file

	:param name: The file and path to be processed
	:returns: The processed filename
	'''

	return os.path.splitext(os.path.basename(name))[0]


def init():
	'''
	Creates some files and a folder to start with a new project. Existing files will not be overwritten.

	:creates: .gitignore
	:creates: limits.txt
	:creates: proteinlist.txt
	:creates: tree_config.txt
	:creates: tree_to_prune.txt
	:creates: heatmap_template.html
	:creates: fastas/
	:creates: blastresults/
	'''

	os.makedirs('fastas', exist_ok=True)
	os.makedirs('blastresults', exist_ok=True) # In case the user runs Blast separately

	orig_dir = os.path.dirname(os.path.realpath(__file__))

	if not os.path.isfile('.gitignore'):
		with open('.gitignore', 'w') as out, open(os.path.join(orig_dir, 'templates/gitignore')) as f:
			out.write(f.read())

	if not os.path.isfile('limits.txt'):
		with open('limits.txt', 'w') as out, open(os.path.join(orig_dir, 'templates/limits.txt')) as f:
			out.write(f.read())

	if not os.path.isfile('proteinlist.txt'):
		with open('proteinlist.txt', 'w') as out, open(os.path.join(orig_dir, 'templates/proteinlist.txt')) as f:
			out.write(f.read())

	if not os.path.isfile('tree_config.txt'):
		with open('tree_config.txt', 'w') as out, open(os.path.join(orig_dir, 'templates/tree_config.txt')) as f:
			out.write(f.read())

	if not os.path.isfile('tree_to_prune.txt'):
		with open('tree_to_prune.txt', 'w') as out, open(os.path.join(orig_dir, 'templates/tree_to_prune.txt')) as f:
			out.write(f.read())

	if not os.path.isfile('heatmap_config.txt'):
		with open('heatmap_config.txt', 'w') as out, open(os.path.join(orig_dir, 'templates/heatmap_config.txt')) as f:
			out.write(f.read())

	if not os.path.isfile('heatmap_template.html'):
		with open('heatmap_template.html', 'w') as out, open(os.path.join(orig_dir, 'templates/heatmap_template.html')) as f:
			out.write(f.read())

	if not os.path.isfile('crosshits.txt'):
		with open('crosshits.txt', 'w') as out, open(os.path.join(orig_dir, 'templates/crosshits.txt')) as f:
			out.write(f.read())


def run_blast(db):
	'''
	Blasts a list of files.

	:param db: The database to blast against
	:creates: `blastresults/*.xml`
	'''

	os.makedirs('blastresults', exist_ok=True)

	if not db:
		raise ValueError('blastdb is empty. Run this script with -d /path/to/blastdb')

	file_list = CR.get_protein_files(prefix = 'fastas/', suffix = '.fasta')
	outstring = 'Now blasting {:' + str(len(str(len(li)))) + 'd}/{}: {}'

	for i, filename in enumerate(file_list):
		print(outstring.format(i+1, len(file_list), filename))
		outfilename = 'blastresults/{}.xml'.format(_my_get_basename(filename))
		phylo.run_blastp(filename, outfilename, db)


def parse_blast_results(do_only = None):
	'''
	Parses Blast results.

	:param do_only: Should be an iterable with filenames that shall be parsed. If all files in `blastresults` shall be parsed, this must evaluate to False.
	:creates: `resulttables/*.tsv`
	'''

	if do_only:
		li = do_only
	else:
		li = CR.get_protein_files(prefix = 'blastresults/', suffix = '.xml')

	os.makedirs('resulttables', exist_ok=True)

	outstring = 'Now parsing {:' + str(len(str(len(li)))) + 'd}/{}: {:<30}'

	for i, filename in enumerate(li):
		basename = _my_get_basename(filename)
		print(outstring.format(i+1, len(li), basename), end='\r')
		parsed_result = phylo.parse_blast_result(filename, TF = TF, top = 0, exclude={118797, 59538, 7213})
		# Contaminants:
		#    118797: Lipotes vexillifer
		#     59538: Pantholops hodgsonii
		#      7213: Ceratitis capitata

		open('resulttables/{}.tsv'.format(basename), 'w').write(parsed_result)


def combine_parsed_results():
	'''
	Combines parsed Blast results.

	:creates: `combinedtables/*.tsv`
	'''

	os.makedirs('combinedtables', exist_ok=True)

	limits = CR.get_limits()
	proteins = CR.get_protein_dict(prefix = 'resulttables/', suffix = '.tsv')

	for k in sorted(proteins):
		print('combining tsv files... {:<40}'.format(k), end='\r')
		outfn = 'combinedtables/{}.tsv'.format(k)
		try:
			max_evalue, min_length = limits[k]
		except KeyError:
			max_evalue, min_length = limits['default']
		header = True

		combined = phylo.combine_parsed_results(proteins[k], max_evalue, min_length)

		if combined:
			open(outfn, 'w').write(combined)


def tables_for_interactive_heatmap():
	'''
	Combines parsed Blast results for use for interactive heatmaps.

	:creates: `interactivetables/*.tsv`
	'''

	proteins = CR.get_protein_dict(prefix = 'resulttables/', suffix = '.tsv')

	os.makedirs('interactivetables', exist_ok=True)

	for k in sorted(proteins):
		print(k.ljust(50), end='\r')

		entries = phylo.table_for_interactive_heatmaps(proteins[k], TF)

		with open('interactivetables/{}.tsv'.format(k), 'w') as outfile:
			for m in sorted(entries):
				outfile.write('{}\t{}\n'.format(m, entries[m]))


def unique_names():
	'''
	For each protein, creates lists with the species that possess this protein. Two lists are generated: One with unique Species names and one with unique taxonomy ids. In addition a general.names and general.taxids are generated with all Species that occur in the lists of all proteins.

	:creates: `names/*.names`
	:creates: `taxids/*.taxids`
	'''

	os.makedirs('names', exist_ok=True)
	os.makedirs('taxids', exist_ok=True)

	total_names = set()
	total_taxids = set()

	for fn in CR.get_protein_names():
		names, taxids = phylo.unique_names_and_taxids(fn)

		with open('names/{}.names'.format(fn), 'w') as f:
			for name in names:
				f.write(name + '\n')

		with open('taxids/{}.taxids'.format(fn), 'w') as f:
			for taxid in taxids:
				f.write(str(taxid) + '\n')

		total_names.update(names)
		total_taxids.update(taxids)

	with open('names/general.names', 'w') as f:
		for name in sorted(list(total_names)):
			f.write(name + '\n')

	with open('taxids/general.taxids', 'w') as f:
		for taxid in sorted(list(total_taxids)):
			f.write(str(taxid) + '\n')


def make_newick():
	'''
	Creates Newick trees for every taxonomy-id list in the taxids folder.

	:creates: `trees/*.tre`
	'''

	li = CR.get_protein_names(prefix = 'taxids/', suffix = '.taxids')
	li.add('taxids/general.taxids')

	os.makedirs('trees', exist_ok=True)

	sanitizer = phylo.NodeSanitizer()

	for filename in li:
		outfn = 'trees/{}.tre'.format(_my_get_basename(filename))
		newick = phylo.make_newick(filename, sanitizer, TF)

		open(outfn, 'w').write(newick)

	sanitizer.print_bad_chars()


def tree_attributes():
	'''
	For each element in the general tree, determine the proteins (attributes) for this element. Each attribute will be a two-letter string. The meaning of each string will be written to `attributekeys.txt`.

	:uses: `trees/general.tre`
	:creates: `attributekeys.txt` (containing an explanation of the keys)
	:creates: `attributes.txt` (containing the keys for each protein)
	'''

	proteinlist = sorted(list(CR.get_protein_names()))
	filenames = ['trees/{}.tre'.format(name) for name in proteinlist]

	master_tree = open('trees/general.tre').read()

	keys, attributes = phylo.get_keys_and_attributes(proteinlist, filenames, master_tree)

	with open('attributekeys.txt', 'w') as out:
		for key in sorted(keys):
			out.write('{} -> {}\n'.format(key, keys[key]))

	with open('attributes.txt', 'w') as out:
		for k in sorted(attributes):
			out.write('{}\t{}\n'.format(k, ''.join(attributes[k])))


def make_histograms():
	'''
	For each seed protein, the distribution of hits is shown in a histogram.

	:creates: `histograms/*.png`
	'''

	protein_files = CR.get_protein_dict(prefix = 'fastas/', suffix = '.fasta')
	seed_lengths = {}

	for prot in protein_files:
		seed_lengths[prot] = []
		for f in protein_files[prot]:
			with open(f) as fastafile:
				length = 0
				next(fastafile)
				for line in fastafile:
					length += len(line.rstrip())
			seed_lengths[prot].append(length)

	os.makedirs('histograms', exist_ok=True)

	cm = plt.cm.get_cmap('rainbow')

	for protein in sorted(protein_files):
		fn = 'combinedtables/{}.tsv'.format(protein)
		print('Histogram: {:<50}'.format(protein), end='\r')
		values = np.loadtxt(fn, dtype=np.int, comments=None, delimiter='\t', skiprows=1, usecols=(5,))

		mi = np.amin(values)
		ma = np.amax(values)

		if ma - mi <= 1000:
			interval = 10
		elif ma - mi <= 2000:
			interval = 20
		elif ma - mi <= 2500:
			interval = 25
		elif ma - mi <= 5000:
			interval = 50
		else:
			interval = 100

		text = '''Distribution
min: {}
max: {}
average: {:.0f}
median: {:.0f}
total elements: {}

interval: {}'''.format(mi, ma, np.mean(values), np.median(values), values.size, interval)

		seeds = seed_lengths[protein]

		sizes = '''Seed protein(s)
min: {}
max: {}
average: {:.0f}
total seeds: {}'''.format(min(seeds), max(seeds), np.average(seeds), len(seeds))

		middle = int(ma/2 + mi/2)
		middle -= int(middle % interval)
		if middle - 50*interval < 0:
			middle = 50*interval

		bins = list(range(middle - 50*interval, middle + interval * 50 + 1, interval))

		fig = plt.figure(1, figsize=(12,6))
		ax = fig.add_subplot(1,1,1)
		n, bins, patches = ax.hist(values, bins=bins)

		# The following block is to color the bars
		bin_centers = 0.5 * (bins[:-1] + bins[1:])
		col = bin_centers - min(bin_centers)
		col /= max(col)
		for c, p in zip(col, patches):
			plt.setp(p, 'facecolor', cm(c))

		ax.text(0.05, 0.95, text, transform=ax.transAxes, horizontalalignment='left', verticalalignment='top')

		ax.text(0.95, 0.95, sizes, transform=ax.transAxes, horizontalalignment='right', verticalalignment='top')

		fig.savefig('histograms/{}.png'.format(protein))

		fig.clear()


def show_blast_mapping():
	'''
	For each protein, create an overview over where the hits where mapped over the length of the protein.

	:creates: `blastmappings/*.png`
	'''

	os.makedirs('blastmappings', exist_ok=True)

	filenames = sorted(list(CR.get_protein_files()))

	fnt = ImageFont.load_default()

	for filename in filenames:
		print('Mapping {:<50}'.format(filename), end='\r')

		query_length = 0
		with open('fastas/{}.fasta'.format(filename)) as f:
			next(f)
			for line in f:
				query_length += len(line.rstrip())

		counters = [np.zeros(query_length, np.int) for x in range(6)]
		num_hsps = [0] * 6

		with open('blastresults/{}.xml'.format(filename)) as f:
			records = NCBIXML.parse(f)

			for record in records:
				for alignment in record.alignments:
					for hsp in alignment.hsps:
						if hsp.expect > 1e-15:
							n = 0
						elif hsp.expect > 1e-30:
							n = 1
						elif hsp.expect > 1e-60:
							n = 2
						elif hsp.expect > 1e-90:
							n = 3
						elif hsp.expect > 1e-120:
							n = 4
						else:
							n = 5
						counters[n][hsp.query_start - 1:hsp.query_end - 1] += 1
						num_hsps[n] += 1

		ma = [np.amax(counters[n]) * 0.01 for n in range(6)]

		counters = [counters[n] / ma[n] if ma[n] != 0 else np.ones(query_length, np.int) for n in range(6)]


		im = Image.new('RGB', (query_length + 60, 600), (255, 255, 255))
		dr = ImageDraw.Draw(im)

		dr.text((2, 40), '> 1e-15', (0, 0, 0), fnt)
		dr.text((2, 140), '> 1e-30', (0, 0, 0), fnt)
		dr.text((2, 240), '> 1e-60', (0, 0, 0), fnt)
		dr.text((2, 340), '> 1e-90', (0, 0, 0), fnt)
		dr.text((2, 440), '> 1e-120', (0, 0, 0), fnt)
		dr.text((2, 540), '<= 1e-120', (0, 0, 0), fnt)

		for n in range(6):
			dr.text((2, 60 + 100 * n), 'n = {}'.format(num_hsps[n]), (0, 0, 0), fnt)

		colors = [(0, 0, 0), (0, 0, 200), (0, 200, 0), (200, 0, 200), (200, 0, 0), (150, 150, 0)]

		for n in range(int(query_length / 100)):
			col = 160 + n*100
			dr.line([(col, 0), (col, 600)], fill=(125, 125, 125), width=1)

		for n in range(6):
			for col, thickness in enumerate(counters[n]):
				dr.line([(col + 60, n*100), (col + 60, thickness + n*100)], fill=colors[n], width=1)

		#im.show()
		im.save('blastmappings/{}.png'.format(filename))


def similarity_matrix():
	'''
	Creates a similarity matrix of proteins. For each protein, the Blast hits are compared to each other protein. The lowest e-value of each protein-protein combination is saved. This gives an impression of how similar two given proteins are and how much the results overlap.

	:uses: combined parsed Blast results in `combinedtables`
	:creates: `matrix.csv`
	'''

	names = {name: 'combinedtables/{}.tsv'.format(name) for name in CR.get_protein_names()}

	res = phylo.similarity_matrix(names)

	with open('matrix.csv', 'w') as out:
		out.write('\t' + '\t'.join(sorted(names)) + '\n')
		for i, line in enumerate(res):
			out.write(names[i] + '\t' + '\t'.join(map(str, line)) + '\n')


def int_heatmap():
	'''
	Creates an interactive heatmap as html file with javascript.

	:uses: heatmap_template.html
	:creates: out.html
	'''

	taxa_to_check = CR.get_heatmap_taxa()
	colors = CR.get_heatmap_colors()
	method = CR.get_heatmap_clustering()
	proteins_to_check = sorted(list(CR.get_protein_names()))
	template = open('heatmap_template.html').read()

	taxids = {}
	tick_taxons = []
	for i, tax in enumerate(taxa_to_check):
		taxname, taxid = tax.split('^')
		tick_taxons.append(taxname.replace('_', ' '))
		taxids[taxid] = i

	tick_proteins = proteins_to_check[:]

	matrix = []
	for i, protein in enumerate(proteins_to_check):
		matrix.append([-100] * len(taxa_to_check))
		with open('interactivetables/{}.tsv'.format(protein)) as f:
			for line in f:
				lline = line.split()
				if lline[0] in taxids:
					matrix[i][taxids[lline[0]]] = int(lline[1])

	html = phylo.interactive_heatmap(matrix, tick_taxa, tick_proteins, colors, template, method)

	open('out.html', 'w').write(html)


# adapted from similarity_matrix
def get_crosshits(do_only = None, crosscrosshits = False):
	'''
	For each pair of proteins creates a file '{protein1}-{protein2}-crosshits.tsv'
	File has three columns: e-value, number of crosshits, AccID^TaxID for all crosshits (comma-separated)
	Will use the config file 'crosshits.txt', unless given a list of proteins in 'do_only'.

	:param do_only: Should be an iterable with proteinnames that shall be used. If it's Falsy proteins in 'crosshits.txt' will be used instead.
	:creates: `crosshits/*.tsv`
	'''

	if do_only:
		li = do_only
	else:
		with open('crosshits.txt') as f:
			li = list()
			for line in f:
				line = line.rstrip('\n').split('#')[0]
				# no empty lines
				if not line:
					continue

				# This is the only '!...' parameter right now, more could be added
				if line.startswith('!'):
					if line[1:] == 'crosscrosshits':
						crosscrosshits = True
						groups = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50]
					if line[1:] == 'groups':
						groups = sorted(list(map(int, line[1:].split())))
					continue

				li += [line]

	os.makedirs('crosshits', exist_ok=True)

	values = {}
	# set is important! the combined tables dont have unique entries
	taxids = defaultdict(set)

	for name in li:
		values[name] = [set() for _ in range(151)]
		with open('combinedtables/{}.tsv'.format(name)) as f:
			next(f)
			for line in f:
				lline = line.split('\t')
				evalue = lline[4]
				if 'e-' in evalue:
					evalue = int(evalue.split('e-')[1])
					if evalue > 150:
						evalue = 150
				elif evalue == '0.0':
					evalue = 150
				else:
					evalue = 0
				acc = lline[1]
				tax = lline[0]
				# Adding TaxID for later use, Acc-IDs are already unique (and implicate tax-id) so this should change anything
				values[name][evalue].add(acc+'^'+tax)
				if crosscrosshits:
					taxids[tax].add(acc)

	names = sorted(values)

	for i, name1 in enumerate(names):
		for name2 in names[i:]: # skips symmetric combinations
			if name1 == name2:  # don't need to compare with itself
				continue
			acc1 = set()
			acc2 = set()
			common = [set() for _ in range(151)]
			oldhits = set()
			for evalue in range(150, -1, -1):
				acc1.update(values[name1][evalue])
				acc2.update(values[name2][evalue])
				inter = acc1.intersection(acc2)
				common[evalue] = inter - oldhits # only write those hits that are new for this evalue
				oldhits.update(inter)

			with open("crosshits/{0}-{1}.tsv".format(name1, name2), "w") as outf:
				outf.write('#e-value\tnumber-of-crosshits\tAccID^TaxID comma-sep\n')
				for j, line in enumerate(common):
					vals = (j, len(line), ",".join(list(line)))
					outf.write('{0}\t{1}\t{2}\n'.format(*vals))

			if crosscrosshits:
				last = []
				cchits = defaultdict(list)
				for entry in oldhits:
					tax = entry.split('^')[1]
					for n in groups:
						if len(taxids[tax]) <= n:
							cchits[n].append(tax)
							break
					else:
						last = [groups[-1]+1]
						cchits[groups[-1]+1].append(tax)

				with open("crosshits/{0}-{1}-crosscrosshits.csv".format(name1, name2), "w") as out:
					out.write('#This file contains clusters of crosscrosshits\n')
					for n in groups+last:
						if n in last:
							out.write('!>{} crosshits per species\n'.format(n-1))
						elif n-1 and n-1 not in groups:
							if groups.index(n):
								lower = groups[groups.index(n) - 1] + 1
							else:
								lower = 1
							out.write('!{} - {} crosshits per species\n'.format(lower, n))
						else:
							out.write('!{} crosshits per species\n'.format(n))

						out.write(','.join(cchits[n])+'\n')


def cross_histograms():
	combos = [f[:-4] for f in os.listdir('crosshits') if f.endswith('.tsv')]
	data = {}

	for c in combos:
		with open('crosshits/{}.tsv'.format(c)) as f:
			next(f)
			lowest = 0
			d = np.array([range(151), [0]*151], dtype=np.int)
			for line in f:
				ev, num, accs = line.rstrip('\n').split('\t')
				if not lowest and int(num):
					lowest = int(ev)
				d[1][int(ev)] = int(num)
			try:
				highest = max([ev for ev, n in enumerate(d[1]) if n]) # highest ev with non-0 crosshits
			except ValueError:
				highest = 0
			data[c] = (lowest, highest, d)

	for combo in combos:
		print('Histogram: {:<50}'.format(combo), end='\r')
		values = data[combo][2]

		mi = data[combo][0] #(0) 30 or higher
		ma = data[combo][1] #max 150
		if len(values[1][mi:ma]) > 0:
			mean = int(np.mean(values[1][mi:ma]))
			median = int(np.median(values[1][mi:ma]))
		else:
			mean = '-'
			median = '-'

		text = '''Distribution
    min: {}
    max: {}
    average: {}
    median: {}'''.format(mi, ma, mean, median)

		fig = plt.figure(1, figsize=(12, 6))
		ax = fig.add_subplot(1, 1, 1)
		bars = ax.bar(values[0], values[1], width=1)

		ax.text(0.05, 0.95, text, transform=ax.transAxes, horizontalalignment='left', verticalalignment='top')
		ax.set_xlabel('E-value [10^-X]')
		ax.set_ylabel('Number of crosshits')

		fig.savefig('crosshits/{}-distribution.png'.format(combo))

		fig.clear()


tasknames = ['blast', 'parse', 'combine', 'comheat', 'unique', 'newick', 'attrib', 'hist', 'map', 'intheat', 'matrix', 'crosshits', 'crosshist']

tasks = {'blast': ('run Blast', run_blast), # ok
'parse': ('parse Blast results', parse_blast_results), # ok
'combine': ('combine parsed results', combine_parsed_results), # ok
'comheat': ('combine parsed results for heatmaps', tables_for_interactive_heatmap), # ok
'unique': ('create unique lists of names and taxids', unique_names), # ok
'newick': ('create Newick tree for each protein', make_newick), # ok
'attrib': ('determine tree attributes', tree_attributes), # ok
'hist': ('create histograms with Blast hits for each protein', make_histograms),
'map': ('create hit mapping diagrams for each protein', show_blast_mapping),
'intheat': ('create an interactive heatmap (html)', int_heatmap), # ok
'matrix': ('create a similarity matrix of all proteins', similarity_matrix), # ok
'crosshits': ('create files with all blast crosshits of certain proteins', get_crosshits),
'crosshist': ('creates Histograms of e-value distribution for crosshits', cross_histograms)}


def run_workflow(start, end=''):
	'''
	Starts the workflow from `start` until `end`. If `end` is empty, the workflow is run until the last element of the workflow.

	:param start: The name of the first element to run.
	:param end: The name of the last element to run or a falsy value if the workflow shall be run until the end.
	'''

	if start not in tasknames:
		raise ValueError('{} is no valid task.'.format(start))

	if not end:
		endidx = len(tasknames)
	elif end not in tasknames:
		raise ValueError('{} is no valid task.'.format(end))
	else:
		endidx = tasknames.index(end) + 1

	startidx = tasknames.index(start)
	for taskname in tasknames[startidx:endidx]:
		print('{}: "{}"'.format(taskname, tasks[taskname][0]))
		task = tasks[taskname][1]
		task()


if __name__ == '__main__':
	import argparse
	import textwrap

	workflow = '\n'.join(textwrap.wrap("""The following is a list of the workflow. The names or numbers can be used for the -s or -o arguments.""", width = 80))

	workflow += '\n\n' + '\n'.join(('{:>2}. {:<8} {}'.format(i, name, tasks[name][0]) for i, name in enumerate(tasknames)))

	parser = argparse.ArgumentParser(description='This module provides you with tools to run phylogenetic analyses. Exactly one argument must be given.')

	parser.add_argument('-l', '--list', action='store_true', help='Shows the whole workflow with information and exits')
	parser.add_argument('-i', '--init', action='store_true', help='Initiates the working directory with necessary files and folders')
	parser.add_argument('-a', '--all', action='store_true', help='Run the full workflow without Blast')
	parser.add_argument('-b', '--blast', action='store_true', help='Run the full workflow including Blast')
	parser.add_argument('-s', '--startfrom', default='', help='Run from and including this step [e.g. 7 or hist]')
	parser.add_argument('-o', '--only', default='', help='Run only the given step [e.g. 4 or unique]')
	parser.add_argument('-d', '--database', default='', help='Path to the Blast database to use. Only needed when actually running Blast (-b or -[os] blast)')

	args = parser.parse_args()

	if args.list:
		parser.print_help()
		print('')
		print(workflow)
		sys.exit()

	if args.init:
		init()
		sys.exit()

	num_arguments = args.all + args.blast + bool(args.startfrom) + bool(args.only)

	if not (num_arguments == 1 or (num_arguments == 2 and args.database != '')):
		parser.print_help()
		sys.exit()

	blastdb = args.database

	# We need objects of these two classes for most of the functions, so we initialize them here already
	# TaxFinder takes some seconds to load, so this is, what makes loading this module slow.
	TF = TaxFinder()
	try:
		CR = ConfigReader()
	except IOError:
		CR = None

	if args.all:
		run_workflow('parse')
	elif args.blast:
		run_workflow('blast')
	elif args.startfrom:
		try:
			a = int(args.startfrom)
		except ValueError:
			try:
				a = tasknames.index(args.startfrom)
			except ValueError:
				parser.print_help()
		if a < len(tasknames):
			run_workflow(tasknames[a])
		else:
			parser.print_help()
	elif args.only:
		try:
			a = int(args.only)
		except ValueError:
			try:
				a = tasknames.index(args.only)
			except ValueError:
				parser.print_help()
		if a < len(tasknames):
			task = tasks[tasknames[a]][1]
			task()
		else:
			parser.print_help()
	else:
		print('This should not happen!')
		parser.print_help()
else:
	# We need objects of these two classes for most of the functions, so we initialize them here already
	# TaxFinder takes some seconds to load, so this is, what makes loading this module slow.
	TF = TaxFinder()
	try:
		CR = ConfigReader()
	except IOError:
		CR = None

	blastdb = ''
